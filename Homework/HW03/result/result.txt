D:\CXTX_copy\08DeepLearning\Homework\.venv\Scripts\python.exe D:\CXTX_copy\08DeepLearning\Homework\HW03\src\rnn_attention.py 
                                                text  label
1  vastar resources , inc . gary , production fro...      0
2  calpine daily gas nomination - calpine daily g...      0
3  re : issue fyi - see note below - already done...      0
4  meter 7268 nov allocation fyi .\n- - - - - - -...      0
5  mcmullen gas for 11 / 99 jackie ,\nsince the i...      0
Text length statistics:
Mean: 314.69
Median: 156.00
Min: 2
Max: 45450
95th percentile: 953.70

Spam messages (count: 16614):
Mean length: 266.86

Ham messages (count: 16493):
Mean length: 362.88
Training Attention model...
Batch: 100%|██████████| 414/414 [00:04<00:00, 90.36it/s]
Epoch 1: train_loss=0.3600, val_acc=0.8906, val_f1=0.8885
Batch: 100%|██████████| 414/414 [00:04<00:00, 97.04it/s]
Epoch 2: train_loss=0.1799, val_acc=0.9308, val_f1=0.9355
Batch: 100%|██████████| 414/414 [00:04<00:00, 97.14it/s]
Epoch 3: train_loss=0.1437, val_acc=0.9432, val_f1=0.9456
Batch: 100%|██████████| 414/414 [00:04<00:00, 97.08it/s]
Epoch 4: train_loss=0.1450, val_acc=0.9405, val_f1=0.9432
Batch: 100%|██████████| 414/414 [00:04<00:00, 96.99it/s]
Epoch 5: train_loss=0.1289, val_acc=0.9426, val_f1=0.9446
Batch: 100%|██████████| 414/414 [00:04<00:00, 96.69it/s]
Epoch 6: train_loss=0.1173, val_acc=0.9495, val_f1=0.9512
Batch: 100%|██████████| 414/414 [00:04<00:00, 96.78it/s]
Epoch 7: train_loss=0.1096, val_acc=0.9489, val_f1=0.9509
Batch: 100%|██████████| 414/414 [00:04<00:00, 96.84it/s]
Epoch 8: train_loss=0.1133, val_acc=0.9514, val_f1=0.9529
Batch: 100%|██████████| 414/414 [00:04<00:00, 96.81it/s]
Epoch 9: train_loss=0.0960, val_acc=0.9547, val_f1=0.9564
Batch: 100%|██████████| 414/414 [00:04<00:00, 96.72it/s]
Epoch 10: train_loss=0.0946, val_acc=0.9502, val_f1=0.9516
Training RNN model...
Batch: 100%|██████████| 414/414 [00:02<00:00, 156.03it/s]
Epoch 1: train_loss=0.6028, val_acc=0.7021, val_f1=0.7112
Batch: 100%|██████████| 414/414 [00:02<00:00, 170.93it/s]
Epoch 2: train_loss=0.5202, val_acc=0.7045, val_f1=0.7155
Batch: 100%|██████████| 414/414 [00:02<00:00, 171.86it/s]
Epoch 3: train_loss=0.4787, val_acc=0.7042, val_f1=0.7096
Batch: 100%|██████████| 414/414 [00:02<00:00, 171.57it/s]
Epoch 4: train_loss=0.4559, val_acc=0.7215, val_f1=0.7228
Batch: 100%|██████████| 414/414 [00:02<00:00, 171.93it/s]
Epoch 5: train_loss=0.4478, val_acc=0.7154, val_f1=0.7255
Batch: 100%|██████████| 414/414 [00:02<00:00, 171.99it/s]
Epoch 6: train_loss=0.4391, val_acc=0.7366, val_f1=0.7425
Batch: 100%|██████████| 414/414 [00:02<00:00, 171.72it/s]
Epoch 7: train_loss=0.4227, val_acc=0.7221, val_f1=0.7160
Batch: 100%|██████████| 414/414 [00:02<00:00, 172.25it/s]
Epoch 8: train_loss=0.3908, val_acc=0.7447, val_f1=0.7431
Batch: 100%|██████████| 414/414 [00:02<00:00, 172.57it/s]
Epoch 9: train_loss=0.3396, val_acc=0.7332, val_f1=0.7028
Batch: 100%|██████████| 414/414 [00:02<00:00, 171.97it/s]
Epoch 10: train_loss=0.3032, val_acc=0.7640, val_f1=0.7602
Test Attention: {'accuracy': 0.9447463768115942, 'precision': 0.9502398081534772, 'recall': 0.9406528189910979, 'f1': 0.945422010140173}
Test RNN: {'accuracy': 0.7657004830917874, 'precision': 0.7922829581993569, 'recall': 0.7311572700296736, 'f1': 0.7604938271604939}
